Import numpy as np
Import pandas as pd
Import tensorflow as tf
Import matplotlib.pyplot as plt
From sklearn.metrics import accuracy_score
From tensorflow.keras.optimizers import Adam
From sklearn.preprocessing import MinMaxScaler
From tensorflow.keras import Model, Sequential
From tensorflow.keras.layers import Dense, Dropout
from sklearn.model selection import train_test_split
 from tensorflow.keras.losses import MeanSquaredLogarithmicError
path = ‘ ‘ ‘ http://storage.googleapis.com/download. tensorflow.org/data/ecg.csv’ ‘ ‘
data = pd.read_csv(path, header=None)
print(data.shape)
data.head()
TARGET = 140
Features = data.drop(TARGET, axis=1)
Target = data[TARGET]
x_train, x_test, y_train, y_test = train_test_split( 
        features, target, test_size=0.2,
         random_state = 0,  stratify=target
)
x_test.shape
x_train.shape
target.value_counts()
train_index = y_train[y_train == 1].index
train_data = x_train.loc[train_index]
min_max_scaler = MinMaxScaler()

x_train_scaled = min_max_scaler.fit_transform( 
         train_data.copy())
x_test_scaled = min_max_scaler.transform(x_test.copy())
x_train.describe()
pd.DataFrame(x_train_scaled).describe()
class Autoencoder (Model):
‘ ‘ ‘
Parameters
--------------
Output_units: int
      Number of output units

Code_size: int
     Number of units in bottle neck
‘ ‘ ‘

def _init_ (self, output_units, code_size=8):
      super()._init_()
      self.encoder = Sequential(
          Dense(64, activation="relu"), 
          Dropout (0.1),
          Dense(32, activation="relu"),
          Dropout (0.1),
          Dense(16, activation-relu), 
          Dropout (0.1),
          Dense(code size, activation='relu')
])
 self.decoder = Sequential([
     Dense(16, activation="relu),
     Dropout (0.1),
     Dense(32, activation="relu'), 
     Dropout (0.1),
     Dense(64, activation="relu"),
    Dropout (0.1),
    Dense(output units, activation='sigmoid') 
     ])
def call(self, inputs):
     encoded = self.encoder(inputs)
     decoded = self.decoder(encoded)
      return decoded
model = AutoEncoder(output_units=x_train_scaled.shape[1]) 
model.compile(loss='msle', metrics=['mse'],  optimizers=’adam’)

history = model.fit(
       x_train_scaled,
       x_train_scaled,
       epochs=20,
       batch_size=512,
       validation_data=(x_test_scaled, x_test_scaled)
)
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.xlabel('Epochs')
plt.ylabel('MSLE Loss')
plt.legend(['loss', 'val_loss'])
plt.show()
